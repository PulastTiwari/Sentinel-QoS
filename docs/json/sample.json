Project Sentinel-QoS: An AI-Driven Framework for Dynamic Quality of Service EnforcementDeconstructing the Challenge: A Blueprint for VictoryThis section provides a foundational analysis of the Ennovatex AI Challenge, specifically Problem Statement #8. It moves beyond a surface-level reading to establish a strategic framework designed to align with every facet of the evaluation criteria. The objective is to define a powerful project narrative and a Unique Value Proposition (UVP) that will distinguish the proposed solution, "Sentinel-QoS," from all other competitors.Deep Analysis of Problem Statement #8: Beyond the TextA thorough deconstruction of the problem statement reveals not only the explicit requirements but also the implicit technical and strategic challenges that must be addressed to create a winning solution. The problem is not merely an academic exercise in classification but a practical network engineering challenge demanding a complete, end-to-end system.Core Objective DeconstructionThe stated core objective is to "develop an AI model to analyze traffic patterns and predict the application category with high accuracy" for the explicit purpose of enabling "the Network to serve differentiated and curated Quality of Service (QoS) for each type of traffic".1 This statement establishes a direct and unbreakable link between the AI classification task and a tangible network engineering outcome. The success of the project, therefore, is not measured by classification accuracy metrics alone, such as precision or recall. Instead, its ultimate value is determined by its ability to drive intelligent, adaptive network behavior. Any proposed solution must demonstrate this full cycle: from data ingestion and classification to policy enforcement and a measurable impact on network performance. A model that achieves 99% accuracy but fails to translate its predictions into effective QoS management has failed to meet the core objective. This understanding dictates that the system architecture must be holistic, integrating the AI engine with a robust QoS enforcement mechanism.Constraint InterpretationThe problem statement specifies several critical constraints: the model must be effective under "varying traffic conditions, channel states, and coverage scenarios" and in a "Multi-UE Connected Scenario".1 These constraints have profound implications for the technical approach. The requirement for robustness across diverse network conditions strongly suggests that models relying on fragile, hand-engineered statistical features are likely to fail. For instance, features based on packet inter-arrival times can be heavily distorted by network jitter or changes in wireless channel quality, rendering the model unreliable. This pushes the solution decisively towards deep learning models, such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), which have demonstrated the ability to learn more fundamental, invariant features directly from raw or near-raw packet data.2 These models can identify patterns within the encrypted payload and header structures that are less susceptible to environmental network noise. Furthermore, the "Multi-UE" constraint necessitates a scalable and efficient architecture. The system must be capable of processing and classifying traffic streams from numerous concurrent users without becoming a bottleneck itself. This implies that the classification should be performed at a central point (like a network gateway or router) and must be computationally efficient enough to handle the aggregate traffic load.The Implicit Challenge: Real-Time PerformanceWhile not explicitly stated as a numerical constraint, the intended application of the system—providing QoS for latency-sensitive applications like "Audio Calls, Video Calls, Gaming"—imposes a stringent real-time performance requirement.1 For QoS to be effective, the classification and subsequent policy enforcement must occur with minimal delay. A system that takes several seconds to classify a new traffic flow is useless for managing a real-time video call that is sensitive to millisecond-level latency. This implicit constraint rules out many traditional flow-based classification methods that require observing a large number of packets or even the entire duration of a flow before making a decision.4 The solution must be capable of making accurate predictions based on the initial few packets of a flow, a characteristic known as "fast classification".4 This reinforces the choice of deep learning models that can operate on small time windows of traffic and highlights the need for an optimized implementation that minimizes inference latency, a key consideration in the design of real-world network systems.5Mapping the Path to Victory: Aligning with Hackathon Evaluation CriteriaA winning hackathon project is one that is consciously designed to excel in every category of the evaluation rubric. The Sentinel-QoS project is architected from the ground up to address the specific criteria outlined for both Phase 1 and Phase 2 of the competition.1Novelty of Approach (25%): The innovation of Sentinel-QoS does not lie in the invention of a new neural network architecture, which is often impractical in a time-constrained hackathon setting. Instead, its novelty stems from the holistic, end-to-end integration of a state-of-the-art spatio-temporal deep learning model with a real-world, standards-based QoS enforcement mechanism, specifically the Differentiated Services (DiffServ) framework. This creates a closed-loop, autonomous system that observes network traffic, intelligently decides on a policy, and acts upon it in real-time. This concept of an AI-driven, self-optimizing network is a major theme in advanced networking research and represents a significant step beyond a simple classification model.6 The project's novelty is in its practical realization of this advanced concept.Technical Implementation & Documentation (25%): Excellence in this category will be achieved through a rigorous and well-justified technical approach. The project will be built upon proven, high-performance architectures, drawing inspiration from seminal works like the "Deep Packet" paper.9 It will utilize a well-established benchmark dataset, ISCXVPN2016, to train and validate the model, ensuring the results are credible and reproducible.10 The QoS enforcement layer will be implemented using industry-standard Linux kernel tools, namely tc and iptables, demonstrating a deep understanding of practical network administration.12 The documentation will be meticulous, referencing academic papers and IETF Request for Comments (RFCs) to provide a solid theoretical and practical justification for every design choice.UI/UX Design or User Interaction Design (15%) & Demo Video (25%): These criteria, accounting for a combined 40% of the Phase 1 score, are often underestimated by technical teams. The project will feature a compelling web-based dashboard that provides a real-time, intuitive visualization of the entire Sentinel-QoS pipeline. This dashboard will not be a mere afterthought; it is a critical component for storytelling. It will display incoming traffic from simulated User Equipments (UEs), the AI's instantaneous classification output, the corresponding QoS policy being applied (e.g., the assigned DSCP value), and the resulting impact on performance metrics like latency and bandwidth. This visual evidence transforms an abstract and complex backend process into a tangible, impressive, and easily understandable demonstration of the system's power.Ethical Considerations & Scalability (10%): These aspects will be addressed explicitly and proactively. Ethical concerns regarding traffic analysis will be mitigated by designing the system to operate on encrypted traffic without decryption, thus preserving user privacy and confidentiality.14 The project's narrative will emphasize that its purpose is network performance optimization for a better user experience, not surveillance or content inspection. Scalability will be addressed by designing a packet-level classifier that can be parallelized across multiple CPU or GPU cores. Furthermore, the documentation will propose a clear path to large-scale deployment within a Software-Defined Networking (SDN) architecture, where the Sentinel-QoS engine acts as an intelligent application on an SDN controller. This aligns with modern network management paradigms and demonstrates forward-thinking design.16Unique Value Proposition (30% - Phase 2): This is the central theme of the project, which will be elaborated upon in the following section. It encapsulates the core narrative and differentiates the project from all potential competitors.Defining the Unique Value Proposition (UVP): From Classifier to Intelligent Network OrchestratorThe most critical strategic decision in this hackathon is how to frame the project. A narrow focus on the AI model will fail to capture the judges' imagination. The project's identity must be elevated to reflect its full potential and impact.The NarrativeThis project is not about building a "traffic classifier." It is about creating "Sentinel-QoS," an autonomous network orchestration agent. This powerful narrative reframes the entire endeavor. Sentinel-QoS is not a passive tool; it is an active, intelligent agent that proactively monitors the network, understands user intent by identifying their applications through their traffic fingerprints, and dynamically orchestrates network resources to guarantee an optimal Quality of Experience (QoE) for every user, on every device, in real-time. This story is compelling, ambitious, and directly addresses the core purpose of the problem statement.Key DifferentiatorsThe Sentinel-QoS narrative is supported by three key technical differentiators that will be emphasized throughout the project's documentation, demo, and presentation:Autonomous Control Loop: Unlike traditional QoS systems that rely on static, manually configured rules, Sentinel-QoS implements a dynamic feedback loop: Classify -> Decide -> Act -> Monitor. It continuously adapts to changing network traffic patterns without human intervention, making the network truly intelligent and self-optimizing.Encryption Agnostic: The system is designed from the ground up to operate effectively on fully encrypted traffic. This is a critical capability in the modern internet, where traditional methods like Deep Packet Inspection (DPI) are rendered ineffective.4 This positions Sentinel-QoS as a future-proof solution.End-to-End Solution: The project bridges the often-separate domains of academic AI research (the classification model) and practical network operations (the QoS enforcement). By presenting a complete, deployable concept that covers the entire process from packet capture to traffic shaping, Sentinel-QoS demonstrates a level of completeness and real-world applicability that is characteristic of winning hackathon projects.18The strategic framing of the project as an "autonomous network orchestration agent" is a direct response to the structure of the problem and the nature of hackathon evaluations. The problem statement asks for a classifier to enable QoS, a clear cause-and-effect relationship.1 Many teams will likely focus heavily on the "cause"—the AI model—and treat the "effect"—the QoS implementation—as a minor detail. However, the evaluation criteria, particularly the 30% weighting for "Unique Value Proposition" and 30% for "Demonstration" in the final phase, indicate that judges are looking for impactful, holistic solutions.1 An analysis of successful hackathon projects reveals a clear pattern: they present themselves as complete systems or autonomous agents that solve a significant real-world problem.18 Therefore, by adopting the Sentinel-QoS narrative, the project aligns perfectly with the problem's core purpose and the judging psychology that rewards comprehensive, visionary solutions over narrow, academic exercises. This narrative provides a robust and compelling foundation for every aspect of the final submission.The State of the Art in Encrypted Traffic ClassificationTo build a novel and technically robust solution, it is imperative to first understand the existing landscape of network traffic classification. This section provides a critical review of historical and current methodologies, establishing the academic and technical foundation for the Sentinel-QoS architecture. It will demonstrate a deep understanding of the problem domain and justify the proposed architectural choices by systematically analyzing the evolution of the field and the performance of state-of-the-art techniques.A Critical Review of Methodologies: The Shift to Machine LearningThe field of network traffic classification has undergone several paradigm shifts, driven primarily by the evolution of internet protocols and applications. Understanding this evolution is key to appreciating why deep learning has become the dominant approach for modern, encrypted networks.Legacy Methods and Their LimitationsHistorically, the first and simplest method for traffic classification was Port-Based Classification. This technique relies on matching the source or destination port numbers in a packet's transport layer header (e.g., TCP or UDP) to the list of well-known ports registered by the Internet Assigned Numbers Authority (IANA), such as port 80 for HTTP or port 443 for HTTPS.4 While computationally simple and fast, this method has become largely unreliable. Many modern applications use dynamic or random ports, and others intentionally use well-known ports of other services to bypass firewalls, a practice known as port masquerading.4To overcome these limitations, the industry developed Deep Packet Inspection (DPI). DPI techniques examine the actual payload of data packets, searching for specific signatures or protocol-specific patterns that uniquely identify an application.4 For a time, DPI was the gold standard for accurate classification. However, its efficacy has been decimated by the widespread adoption of end-to-end encryption protocols like TLS and QUIC. When traffic is encrypted, the packet payload becomes an unintelligible stream of bytes, rendering signature-based inspection impossible.14 Furthermore, DPI raises significant privacy concerns and can be computationally expensive, making it unsuitable for high-speed networks.4The Rise of ML/DLThe failure of legacy methods in the face of encryption prompted a shift towards a new paradigm: Machine Learning (ML). Instead of inspecting the packet payload, ML-based approaches focus on the statistical properties of the traffic flow. These methods extract features that are observable even when the traffic is encrypted, such as packet lengths, packet inter-arrival times, flow duration, and the number of bytes sent and received.2 These features form a statistical fingerprint of an application's behavior. For example, a video stream might be characterized by a long-duration flow with a relatively consistent stream of large packets, while an interactive SSH session would consist of short, sporadic packets. Classical ML algorithms like Support Vector Machines (SVM), k-Nearest Neighbors (k-NN), and Random Forest have been successfully applied to these statistical features to classify traffic.14The latest evolution in this domain is the application of Deep Learning (DL). DL models take the ML approach a step further by automating the feature extraction process, a concept known as representation learning.15 Instead of relying on manually engineered statistical features, DL architectures like CNNs and LSTMs can learn discriminative patterns directly from raw or near-raw packet data. This has proven to be a breakthrough for encrypted traffic classification, as these models can identify subtle, complex patterns in packet sizes, timings, and even the byte-level distributions of the encrypted payload that are not captured by traditional statistical features.3 This ability to learn directly from the data makes DL models more robust, more accurate, and better able to adapt to new and evolving applications.Architectural Deep Dive: A Comparative AnalysisThe choice of deep learning architecture is a critical design decision that directly impacts the performance, complexity, and real-time viability of the classification engine. A comparative analysis of the most relevant architectures, informed by comprehensive surveys and research papers, provides a clear rationale for selecting a hybrid approach.3Stacked Autoencoders (SAEs): An autoencoder is a type of neural network primarily used for unsupervised learning. It is trained to reconstruct its input, forcing it to learn a compressed, internal representation of the data in its smaller hidden layers.3 SAEs are created by stacking multiple autoencoders. In traffic classification, they can be used to pre-train a model on a large unlabeled dataset to learn robust features, which are then fine-tuned on a smaller labeled dataset. While this approach can be effective, particularly for dimensionality reduction, studies have shown that for the specific task of encrypted traffic classification, architectures like CNNs often achieve higher accuracy when trained directly on the raw data.9Convolutional Neural Networks (CNNs): Originally designed for image processing, CNNs have been adapted with great success for traffic classification. A flow or a single packet can be represented as a 1D vector or a 2D image of its byte content. CNNs apply a series of learnable filters (kernels) across this input, allowing them to capture spatial features—localized patterns in the byte sequence of a packet header or encrypted payload.3 This is highly effective because different protocols and applications, even when encrypted, leave behind structural artifacts that CNNs can detect. The "Deep Packet" paper provides a prime example of a 1D-CNN achieving state-of-the-art performance by treating each packet as a 1500-byte vector.9 The key advantage of CNNs is their ability to learn these features automatically while being computationally more efficient than fully connected networks for high-dimensional inputs.3Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM): RNNs are specifically designed to handle sequential data. They maintain an internal state or "memory" that allows them to process sequences of inputs, making them ideal for capturing temporal dependencies in a traffic flow.3 For example, an LSTM (a sophisticated type of RNN that avoids issues with long-term memory) can learn the characteristic sequence of packet sizes and timings that define an application's behavior over time. A video call might have a steady back-and-forth pattern of medium-sized packets, while a file download will have a sequence of small request packets followed by a long burst of large data packets. This ability to model the temporal nature of a flow is a powerful complement to the spatial feature extraction of CNNs.22Hybrid Models (CNN-LSTM): Recognizing the complementary strengths of CNNs and LSTMs, researchers have developed hybrid architectures that combine them. In a typical CNN-LSTM model for traffic classification, the initial layers are convolutional. They process each packet in a sequence individually to extract a rich vector of spatial features. This sequence of feature vectors is then fed into an LSTM layer, which models the temporal relationships between the packets.3 This hybrid approach allows the model to learn both what the packets look like (CNN) and the order in which they appear (LSTM). This combination has been shown to outperform either architecture alone, as it captures a more complete picture of the application's traffic signature, and thus represents the current state of the art for this problem.10Foundational Research: Lessons from "Deep Packet"The 2017 paper "Deep Packet: A Novel Approach For Encrypted Traffic Classification Using Deep Learning" serves as a foundational blueprint for the Sentinel-QoS AI engine.9 A close analysis of its methodology provides several critical, practical lessons that directly inform the proposed implementation.9Input Representation: The paper validates the approach of using raw packet data as the model's input. It represents each IP packet as a fixed-length vector of its first 1500 bytes (IP header plus payload). This demonstrates that it is not necessary to engineer complex statistical features; the deep learning model can learn directly from the byte stream.Preprocessing is Crucial: "Deep Packet" details a series of essential preprocessing steps that must be replicated. These include removing the link-layer (Ethernet) header, which contains information irrelevant to application classification, and, most importantly, masking the source and destination IP addresses. This step is critical to prevent the model from "cheating" by simply memorizing the IP addresses of known services (e.g., Google or Netflix servers). By zeroing out the IP addresses, the model is forced to learn from the actual traffic patterns, making it far more generalizable. The paper also standardizes packet lengths through zero-padding, a necessary step for batch processing in neural networks.9Benchmark Performance: The paper reports outstanding results on the ISCX VPN-nonVPN dataset, achieving a recall of 0.98 for application identification using its CNN model. This not only sets a high performance bar for the Sentinel-QoS project but also validates the choice of this specific dataset as a suitable and challenging benchmark for development and evaluation.9Packet-Level vs. Flow-Level Analysis: A key advantage of the "Deep Packet" approach is that it operates at the packet level. While it classifies the application associated with the flow, it can make this prediction based on individual packets. This is fundamentally more suited to real-time QoS applications than traditional flow-based methods that require the capture and analysis of an entire traffic flow, which could last for minutes or hours. This packet-centric design is essential for the low-latency response required by Sentinel-QoS.9The following table provides a systematic summary of the deep learning architectures, justifying the selection of a hybrid CNN-LSTM model as the optimal choice for the Sentinel-QoS engine.Table 1: Comparative Analysis of Deep Learning Architectures for Traffic ClassificationArchitectureInput Data FormatKey StrengthsWeaknesses/ChallengesRelevant ResearchSuitability for Problem #8MLPStatistical FeaturesSimple to implement.Low accuracy on complex/encrypted traffic; requires manual feature engineering.3LowCNNRaw Packet Bytes (1D/2D)Learns spatial features; high accuracy on encrypted data; reduces parameters.Lacks inherent understanding of temporal sequence across packets.3HighRNN/LSTMSequence of Packet FeaturesLearns temporal dependencies in a flow; ideal for sequential data.Can be computationally intensive; may miss spatial features within packets.3HighAutoencoderStatistical or Raw DataUnsupervised feature learning; dimensionality reduction.Often used for pre-training; less common as a primary classifier.3MediumHybrid CNN-LSTMSequence of Raw PacketsCombines spatial feature extraction (CNN) with temporal sequence modeling (LSTM).Higher complexity to implement and train.3OptimalThe Sentinel-QoS Architecture: A Novel Hybrid ApproachThis section presents the detailed technical architecture of the Sentinel-QoS system. It outlines a novel, integrated framework that combines a state-of-the-art deep learning model for traffic classification with a standards-compliant mechanism for QoS policy enforcement. This architecture represents the core technical contribution of the project, demonstrating a complete, end-to-end solution that translates AI-driven insights into direct network action.Conceptual Overview: The Autonomous QoS LoopThe Sentinel-QoS system is designed as a continuous, autonomous control loop that dynamically manages network traffic. This loop consists of four distinct stages, which operate in a seamless, real-time cycle. A high-level conceptual diagram of this process illustrates the flow of data and control within the system.Capture: The process begins at a network ingress point, such as a gateway router or a virtual switch. A lightweight packet capture module, implemented using efficient, low-level tools like tcpdump or the libpcap library, intercepts traffic from multiple User Equipments (UEs). This module is designed to be highly performant, sniffing packets from the network interface with minimal overhead.Classify: The captured packet data, specifically the initial packets of each new traffic flow, are passed to the core of the system: the Sentinel-QoS AI Engine. This engine, built around a sophisticated deep learning model, analyzes the spatio-temporal patterns within the packet data to predict the application category (e.g., Video Call, Gaming, File Download) in real-time.Mark: Once the AI engine makes a prediction, the result is sent to the QoS Enforcement Module. This module's first action is to "mark" the traffic. Using the iptables utility within the Linux kernel, it modifies the Differentiated Services (DS) field in the IP header of all subsequent packets belonging to that flow, setting a specific Differentiated Services Code Point (DSCP) value that corresponds to the classified application category.Shape: The final stage occurs as the marked packets are queued for transmission. The network interface's queuing discipline, configured using the tc (traffic control) utility, reads the DSCP mark on each packet. Based on this mark, it directs the packet to a specific traffic class or queue, each with its own pre-defined QoS policy (e.g., higher priority, guaranteed bandwidth). This ensures that latency-sensitive traffic is expedited while bulk traffic is managed to prevent congestion, thereby enforcing the differentiated service.This four-stage loop transforms the network from a passive conduit into an intelligent, adaptive system that autonomously prioritizes traffic based on a deep understanding of application behavior.The Core AI Engine: A Spatio-Temporal CNN-LSTM ModelThe heart of Sentinel-QoS is its AI engine, which employs a hybrid deep learning architecture designed to capture the complex fingerprints of encrypted network traffic. This model combines the strengths of Convolutional Neural Networks (CNNs) for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal sequence analysis.Input RepresentationTo provide the model with a rich, multi-dimensional view of a traffic flow, the input is structured as a 2D tensor. This approach enhances the methodology used in the "Deep Packet" study.9 Each traffic flow is represented by a sequence of its first N packets (e.g., N=10). Each of these packets is, in turn, represented by its first M bytes (e.g., M=784). This creates an input tensor of shape (N×M) for each classification instance. This representation is powerful because it captures both the intra-packet spatial patterns (the byte layout within each packet) and the inter-packet temporal patterns (the sequence of different packet types). Research indicates that the initial packets of a flow often contain the most discriminative information for classification, making this a highly efficient approach for real-time systems.3Model ArchitectureThe deep learning model is architected as a sequential pipeline of specialized layers, each performing a specific function in the feature learning process.CNN Layers: The input tensor is first processed by a series of 1D Convolutional layers. These layers apply filters along the byte dimension (M) of each of the N packet vectors. This step acts as a powerful, learned feature extractor, identifying recurring low-level spatial patterns in the raw byte streams of the encrypted headers and payloads. For example, the CNN might learn to recognize the fixed-size structures of a TLS handshake or the characteristic byte patterns produced by a specific video codec's encryption scheme.LSTM Layer: The output of the CNN layers is a sequence of N feature vectors, where each vector is a high-level representation of a single packet. This sequence is then fed into an LSTM layer. The LSTM layer is designed to model sequential data; it learns the temporal dependencies and patterns in the sequence of packet features. This allows it to distinguish between applications based on their behavioral dynamics—for instance, the steady, bidirectional exchange of packets in a voice call versus the bursty, unidirectional flow of a video stream.Dense Layers: Finally, the output from the LSTM layer, which encapsulates both spatial and temporal information about the flow, is passed through one or more fully connected (Dense) layers. These layers perform the final classification task. The last layer uses a Softmax activation function, which outputs a probability distribution across all the target application categories.Target ClassesThe model will be trained as a multi-class classifier to predict the specific application categories outlined in the problem statement: Video Streaming, Audio Calls, Video Calls, Gaming, Video Uploads, Browsing, and Texting.1 An additional "Other" or "Default" class will be included to handle traffic that does not fit into these predefined categories.The QoS Enforcement Module: Bridging AI to Network ActionThe most innovative aspect of the Sentinel-QoS architecture is its ability to translate the AI model's abstract predictions into concrete network control actions. This is achieved by implementing the industry-standard Differentiated Services (DiffServ) framework using native Linux networking tools.The DiffServ FrameworkDiffServ is a scalable and widely adopted architecture for providing Quality of Service in IP networks.26 It avoids the scalability problems of older QoS models by pushing complex classification tasks to the edge of the network while keeping the core network's function simple. The framework consists of two key components:Packet Marking (at the network edge): At the point where traffic enters the managed network, a classifier inspects the traffic and "marks" each packet by setting a value in the 6-bit Differentiated Services Code Point (DSCP) field within the IP header.26 In the Sentinel-QoS system, the AI engine serves as this advanced, intelligent classifier.Per-Hop Behavior (PHB) (in the network core): As packets traverse the network, each router and switch simply examines the DSCP value and applies a corresponding, pre-configured forwarding treatment, or Per-Hop Behavior. For example, a packet marked with the "Expedited Forwarding" (EF) DSCP will be placed in a high-priority, low-latency queue, regardless of the application it belongs to. This makes the core network's job simple and fast.26Implementation with Linux ToolsThe Sentinel-QoS prototype will implement the DiffServ framework on a single Linux machine (acting as a router or gateway) using two powerful, standard utilities:iptables for Marking: The iptables firewall utility has a mangle table that allows for the modification of packet headers. The output of the AI model (the predicted application class) will trigger a system call to an iptables command. This command will use the DSCP target to set the appropriate DSCP value for all packets belonging to the newly classified flow (identified by its 5-tuple). This effectively translates the AI's prediction into a standard network-level signal.13tc for Shaping: The tc (traffic control) utility is used to configure the kernel's packet scheduling and shaping policies on a network interface.12 A classful queuing discipline (qdisc), such as the Hierarchical Token Bucket (HTB), will be configured on the egress interface. HTB allows for the creation of a hierarchy of traffic classes, each with its own guaranteed bandwidth rate and borrowing priority.31 A tc filter will then be set up to inspect the DSCP mark of each outgoing packet and direct it to the appropriate HTB class. This is the mechanism that actually enforces the QoS policy, ensuring that packets from high-priority classes are sent before those from low-priority classes.33System Workflow: End-to-End Data and Control FlowA detailed sequence diagram can illustrate the complete, end-to-end journey of packets through the Sentinel-QoS system, highlighting the interplay between the different components.A packet from a new, unclassified flow arrives at the network interface of the Sentinel-QoS gateway.The packet capture module sniffs the packet and extracts its byte representation.The packet data is sent to the Python-based AI service, which buffers it along with other initial packets from the same flow.Once enough packets (N) are collected, the AI engine performs inference on the resulting (N×M) tensor, classifying the flow's application category.The predicted category (e.g., "Gaming") is looked up in the Sentinel-QoS Policy Map (Table 2) to determine the corresponding DSCP value (e.g., 46 for EF).The system makes a system call to iptables, creating a rule in the mangle table that matches the flow's 5-tuple and sets the DSCP field to the determined value for all subsequent packets in that flow.As these newly marked packets are processed for egress, the Linux kernel's tc queuing discipline on the network interface examines their DSCP value.The tc filter directs the packets to the high-priority queue configured for the EF class.The packet is dequeued and forwarded with minimal delay, receiving the appropriate QoS treatment.This tightly integrated workflow enables the system to react to new traffic flows within seconds, providing dynamic and intelligent QoS management. The following policy map serves as the critical translation layer that connects the AI's intelligence to the network's behavior.Table 2: Sentinel-QoS Policy Map: Application Category to DiffServ MappingPredicted CategoryQoS RequirementRecommended DSCP Class (RFC 4594)DSCP Valueiptables Marking Exampletc Class ExampleAudio/Video CallsLow Latency, Low JitterExpedited Forwarding (EF)46 (0x2e)-j DSCP --set-dscp-class EFHigh priority, low latency queueGamingLow Latency, Low JitterExpedited Forwarding (EF)46 (0x2e)-j DSCP --set-dscp-class EFHigh priority, low latency queueVideo StreamingHigh Throughput, Jitter-tolerantAssured Forwarding 41 (AF41)34 (0x22)-j DSCP --set-dscp-class AF41Guaranteed bandwidth queueVideo UploadsHigh ThroughputAssured Forwarding 31 (AF31)26 (0x1a)-j DSCP --set-dscp-class AF31Medium priority, high bandwidthBrowsing / TextingInteractiveAssured Forwarding 21 (AF21)18 (0x12)-j DSCP --set-dscp-class AF21Best effort queueBackground/DownloadsNon-criticalClass Selector 1 (CS1)8 (0x08)-j DSCP --set-dscp-class CS1Low priority, scavenger queueDefaultBest EffortDefault Forwarding (DF)0 (0x00)-j DSCP --set-dscp-class BEDefault queueData Strategy and PreparationThe performance and robustness of any machine learning system are fundamentally determined by the quality and relevance of its training data. This section outlines a comprehensive data strategy for the Sentinel-QoS project, including the selection of a benchmark dataset, a detailed pipeline for data ingestion and preprocessing, and a discussion of the feature representation that will be fed into the AI engine.Dataset Selection: The ISCX VPN-nonVPN 2016 DatasetThe hackathon rules explicitly permit the use of publicly available open data.1 After a thorough review of available resources, the ISCX VPN-nonVPN 2016 dataset from the University of New Brunswick is identified as the optimal choice for this project. This selection is justified by several key factors:High Relevance: The dataset is specifically designed for the task of classifying encrypted and VPN-encapsulated traffic, which is the central challenge of Problem Statement #8.2 It contains traffic captures from sessions where applications are used both over a direct connection and through a VPN, providing a rich source of encrypted data patterns.Benchmark Status: ISCXVPN2016 is a widely recognized and frequently used benchmark in the academic community for network traffic classification research. Its use in seminal papers like "Deep Packet" establishes it as a credible standard for evaluating model performance and allows for direct comparison with state-of-the-art results.9 Using a well-known benchmark lends significant technical credibility to the project.Rich and Granular Labels: The dataset provides labeled traffic captures for a variety of application types that align closely with the categories required by the problem statement. These include VoIP (for audio/video calls), video streaming, file transfers (for uploads/downloads), browsing, and chat (for texting).9 This granularity is essential for training a multi-class classifier that can provide the differentiated QoS needed.Public Availability and Tooling: The dataset is publicly accessible, and numerous open-source tools and GitHub repositories exist for processing its .pcap files.11 This existing ecosystem of tools can significantly accelerate the data preparation phase, which is a critical advantage in a time-constrained hackathon environment.While other datasets, such as those available on Kaggle, could potentially be used for supplementary data or pre-training if time allows, the ISCXVPN2016 dataset will serve as the primary source for training and evaluation due to its superior alignment with the project's specific requirements.36Data Ingestion and Preprocessing PipelineA robust, automated pipeline is required to transform the raw network captures from the dataset into the clean, structured tensors needed by the deep learning model. This pipeline will be implemented as a series of Python scripts, following best practices established in the research literature and open-source projects.11Step 1: PCAP Ingestion: The process begins by downloading the raw .pcap files from the official dataset source.35 These files contain the complete, byte-for-byte network captures for each session.Step 2: Flow Extraction: The raw packets within the .pcap files must be grouped into bidirectional flows. A flow is uniquely identified by its 5-tuple: source IP address, destination IP address, source port, destination port, and protocol (TCP or UDP). A script utilizing a library like scapy or a command-line tool like tshark will be used to iterate through the .pcap files and aggregate packets into their respective flows.Step 3: Pre-filtering: Not all packets in a capture are useful for application classification. Following the methodology of "Deep Packet" and other successful implementations, the pipeline will filter out packets that contain little to no application-level information.9 This includes TCP handshake packets (SYN, FIN, ACK packets with no payload) and DNS query/response packets, which relate to connection setup rather than the application's ongoing behavior.Step 4: Normalization and Sanitization: This is the most critical stage of preprocessing, designed to clean the data and ensure the model learns generalizable patterns.Header Stripping: The link-layer header (e.g., Ethernet header) is removed from each packet, as it contains physical network information (like MAC addresses) that is irrelevant for application-level classification.IP Address Masking: To prevent the model from overfitting to specific server IP addresses, the source and destination IP addresses in the IP header of every packet will be masked or zeroed out (e.g., set to 0.0.0.0).9 This forces the model to learn from the content and structure of the traffic itself, not from easily memorized network endpoints.Packet Length Standardization: Deep learning models require inputs of a fixed size. Each packet will be either truncated to a fixed length M (e.g., 1500 bytes) or, if it is shorter than M, padded with zero bytes at the end to reach that length.Byte Value Normalization: The value of each byte in the packet (ranging from 0 to 255) will be normalized to a floating-point number between 0.0 and 1.0 by dividing by 255. This is a standard practice that improves the stability and convergence of neural network training.Step 5: Sessionization: For each extracted and cleaned flow, the pipeline will select the first N packets (e.g., N=10). These N packets, each of length M, will be stacked to form the final (N×M) tensor that serves as a single input sample for the model.Step 6: Data Balancing: Traffic datasets are often highly imbalanced, with common applications like web browsing representing a much larger volume of data than less frequent ones. To prevent the model from becoming biased towards the majority classes, a data balancing strategy will be employed. This may involve under-sampling the majority classes by randomly discarding some of their samples, or over-sampling the minority classes using techniques like SMOTE (Synthetic Minority Over-sampling Technique) or, if time permits, employing a Generative Adversarial Network (GAN) to create synthetic samples for the under-represented classes.3Feature Representation for the AI EngineThe design of the input features is a pivotal decision that reflects the core philosophy of the deep learning approach. While traditional machine learning is dependent on a process of manual feature engineering, the Sentinel-QoS engine leverages the power of representation learning, treating the raw data itself as the feature.The choice to use a 2D tensor of raw packet bytes as the input is a deliberate one. Traditional ML approaches would first compute a vector of statistical features from this data—mean packet size, standard deviation of inter-arrival time, etc..2 However, this process inherently loses information and relies on the assumption that these chosen statistics are the most discriminative ones. Encryption further complicates this, as it obscures many of the patterns that these statistics are designed to capture.15The success of models like "Deep Packet" has demonstrated that deep neural networks, particularly CNNs, can find meaningful patterns even in the seemingly random byte streams of encrypted payloads.9 These patterns are not truly random; they are subtle artifacts of the underlying application data, the transport protocol's framing, and the specific implementation of the encryption algorithm. For example, a particular video codec might generate frames of a consistent size, which, even when encrypted, result in IP packets of a predictable length. A TLS handshake has a very specific sequence of message types and lengths. By feeding the model the raw byte stream, it is empowered to discover these and other, more complex, non-linear patterns on its own.In this paradigm, the "feature" is the raw, structured data itself. The representation of a flow as a 2D tensor of packet bytes can be conceptualized as creating a unique "fingerprint" or "image" of that application's behavior. The CNN component of the hybrid model acts as a learned feature extractor, automatically identifying the most salient motifs and patterns within these fingerprints. The LSTM component then learns the grammar of how these fingerprints are sequenced over time. This approach of feature learning is fundamentally more powerful and robust than feature engineering, as it allows the model to adapt to the full complexity of the data without being constrained by human-preconceived notions of what features are important. This is a key technical strength of the Sentinel-QoS architecture and a critical point to emphasize in the project's technical documentation and final presentation.Implementation Blueprint: A Step-by-Step Execution PlanThis section provides a detailed, pragmatic, and actionable plan for constructing the entire Sentinel-QoS system within the time constraints of a hackathon. The project is broken down into four distinct, manageable phases, with clear objectives, recommended tools, and specific action items for each. This blueprint is designed to guide the team's efforts, ensure parallel workflows, and culminate in a fully integrated and functional prototype.Phase I: Environment Setup and Data Pipeline (First 4-6 hours)The foundation of the project is a reliable and efficient data processing pipeline. This initial phase is dedicated to establishing the development environment and building the scripts necessary to transform raw data into a format suitable for model training.Objective: To have a fully functional and tested data processing pipeline capable of converting the raw .pcap files from the ISCXVPN2016 dataset into model-ready numerical tensors.Tools:Operating System: A Linux-based environment (such as Ubuntu, either running natively, in a VM, or within a Docker container) is essential, as the QoS enforcement module relies on Linux kernel utilities (tc, iptables).Packet Analysis: Wireshark for initial manual inspection and understanding of the .pcap files; tshark and tcpdump for programmatic filtering and data extraction in scripts.38Scripting and Data Handling: Python 3 will be the primary language. Essential libraries include scapy for sophisticated packet manipulation and flow extraction, pandas for intermediate data structuring, and numpy for creating and saving the final multi-dimensional tensor arrays.Action Plan:Environment Configuration: Set up the Linux development environment and install all necessary software packages and Python libraries via a requirements.txt file.Data Acquisition: Download and extract the complete ISCXVPN2016 dataset into a designated project directory.11Pipeline Scripting: Develop the Python scripts to implement the full preprocessing pipeline as detailed in Section 4.2. To accelerate this process, it is highly recommended to adapt and build upon the logic found in existing open-source repositories that work with this dataset.11 The script should automate flow extraction, pre-filtering, normalization (header stripping, IP masking, padding), and sessionization.Data Generation: Execute the completed pipeline on the raw dataset. The output should be three distinct files (e.g., train.npy, val.npy, test.npy and corresponding label files) containing the final, preprocessed tensors. Saving the data in an efficient binary format like NumPy arrays or TensorFlow's tfrecords will be crucial for fast loading during the model training phase.Phase II: Building and Training the Sentinel-QoS AI Engine (Next 10-12 hours)This phase focuses on the core AI component of the project. It involves implementing the deep learning architecture and training it on the data prepared in Phase I. This is typically the most time-consuming single task in the project.Objective: To have a fully trained and validated hybrid CNN-LSTM model that demonstrates high classification accuracy on the held-out test set.Frameworks: A high-level deep learning framework such as TensorFlow with the Keras API or PyTorch should be used. These frameworks provide the necessary building blocks and training infrastructure to rapidly prototype and iterate on the model.Action Plan:Model Implementation: Write the Python code to define the hybrid CNN-LSTM architecture as described in Section 3.2. This involves stacking the 1D Convolutional, MaxPooling, LSTM, and Dense layers using the chosen framework's API.Data Loading: Implement efficient data loaders that can read the preprocessed NumPy or tfrecords files and feed batches of data to the model during training.Training Configuration: Define the training loop. This includes selecting the loss function (Categorical Cross-Entropy for multi-class classification), the optimizer (Adam is a robust default choice), and the evaluation metrics (Accuracy, Precision, Recall, F1-Score).Initiate Training: Start the model training process. Given the size of the dataset and the complexity of the model, this may take several hours. Crucially, work on Phase III should begin in parallel while the model is training.Model Checkpointing: Implement a callback mechanism to periodically save the model's weights during training. The best version of the model, determined by its performance on the validation set, should be saved to prevent losing progress and to ensure the final model is the most optimal one.Evaluation: Once training is complete, load the best saved model and evaluate its performance on the unseen test set. Generate and save key performance metrics, including a confusion matrix to visualize which classes the model is struggling with.Phase III: Developing the QoS Enforcement Module (Parallel with Phase II)While the AI model is training, a separate team member should focus on building and testing the networking component of the system. This module is responsible for applying the QoS policies based on the AI's future classifications.Objective: To create a set of robust scripts that can programmatically configure the Linux kernel's traffic control subsystem to prioritize and shape traffic based on predefined classes.Tools: Linux shell scripting (bash), tc, and iptables.Action Plan:Traffic Control Script (setup_qos.sh): Write a shell script that sets up the necessary queuing discipline on the target network interface (e.g., eth0). This script will use tc commands to delete any existing qdisc, add a root htb qdisc, and create the child classes with their respective bandwidth rates and priorities as defined in the Policy Map (Table 2).31Policy Application Script (apply_policy.py): Write a Python function or script that takes a flow identifier (e.g., a 5-tuple) and an application class name as input. This script will translate the class name into the corresponding DSCP value from the Policy Map and then construct and execute the appropriate iptables command using a system call (e.g., via Python's subprocess module). This command will insert a rule into the mangle table to mark packets for that flow.13Independent Testing: This module must be tested thoroughly in isolation from the AI model. A simple test case can be created using a tool like iperf to generate a known traffic stream. The apply_policy.py script can be called manually to classify this iperf flow as, for example, "Video Uploads." The system's state can then be verified by checking the output of iptables -t mangle -L to see if the marking rule was created and tc -s class show dev eth0 to confirm that the iperf traffic is being counted in the correct htb class.Phase IV: System Integration and End-to-End Testing (Next 6-8 hours)This final development phase involves connecting all the previously built components—the data pipeline, the trained AI model, and the QoS enforcement module—into a single, cohesive, and functional prototype.Objective: To create a working end-to-end system that can capture live traffic, classify it using the AI model, and apply the correct QoS policies in real-time.Action Plan:Orchestration Script (sentinel.py): Develop the main Python script that will serve as the orchestrator for the entire system.Live Packet Capture: Integrate a live packet capture mechanism into sentinel.py using a library like scapy or pyshark. The script will need to run with sufficient privileges to sniff network traffic.Integration Logic: The orchestrator will manage the logic for identifying new flows, collecting their initial N packets, calling the preprocessing functions, and feeding the resulting tensor to the loaded, trained AI model for inference.Connecting the Loop: Upon receiving a classification from the model, the orchestrator will call the apply_policy.py function from Phase III, passing the flow's identifier and the predicted class to complete the control loop.Testbed Creation: Set up a controlled testbed environment. This can be done effectively using network simulation tools like Mininet or by using Docker containers to simulate multiple UEs. These simulated UEs can be configured to generate different types of traffic (e.g., using iperf for bulk transfers, playing a YouTube video for streaming, initiating a VoIP call).End-to-End Validation: Run the complete Sentinel-QoS system on the testbed. Use monitoring tools like Wireshark (to inspect DSCP marks on packets) and tc -s class show dev eth0 (to view traffic statistics per queue) to rigorously verify that the entire system is working as intended—that different traffic types are being correctly classified and shaped according to the defined policies in real-time.Crafting the Winning SubmissionA technically brilliant project can still fail at a hackathon if it is not presented effectively. The final submission—encompassing the demonstration, video, documentation, and strategic messaging—is as critical as the code itself. This section provides a detailed guide to crafting a submission that is compelling, professional, and meticulously aligned with the judging criteria 1, drawing inspiration from the common characteristics of past AI hackathon winners.18Designing an Impactful Demonstration: The UI/UXTo make the complex, backend processes of Sentinel-QoS understandable and impressive to the judges, a simple but powerful real-time dashboard is essential. This visual interface is the key to telling the project's story effectively.Objective: To create a web-based dashboard that visualizes the entire autonomous QoS loop in real-time, transforming abstract network operations into a clear and tangible demonstration of the system's capabilities.Tools: A lightweight Python web framework like Flask or Streamlit is ideal for this purpose. These frameworks allow for the rapid development of data-driven web applications and are frequently seen in winning hackathon projects.18 The dashboard will need to communicate with the main sentinel.py orchestrator, potentially via a simple REST API or a shared message queue.Dashboard Components: The dashboard should be designed with clarity and impact in mind, featuring several key components:Live Traffic Monitor: A panel that lists incoming traffic flows identified by the capture module. It should display basic information for each flow, such as the (simulated) UE source, the destination, and its current status (e.g., "Classifying," "Policy Applied").AI Classification Log: A real-time, auto-scrolling log that provides a transparent view into the AI engine's decision-making process. Each entry should be timestamped and clearly state the outcome, for example: [2024-08-26 14:32:10] Flow classified as [Video_Call] with confidence [98.7%].QoS Policy View: A dynamic table that shows the active QoS policies. It should list each classified flow and the specific policy that has been applied to it, including the assigned DSCP value (e.g., "EF - 46") and the corresponding tc traffic class (e.g., "High Priority").Performance Visualization: This is the most critical component for demonstrating impact. The dashboard should feature live-updating graphs (created with a library like Plotly or Chart.js) that display key performance metrics for each QoS class. For instance, one graph could show the bandwidth usage per class over time, while another could show the average latency. This will provide undeniable visual proof that high-priority traffic (like the video call) is receiving preferential treatment (low latency, stable bandwidth) at the expense of low-priority traffic (the file download), which is the entire point of the system.The 10-Minute Demo Video: A Compelling StoryThe demo video is the primary vehicle for communicating the project's value in Phase 1. It must be a tightly scripted, compelling narrative that is both technically informative and engaging.Structure: The video should follow a classic storytelling arc:(0:00-1:00) The Problem & The Vision: Start by framing the problem: in today's encrypted internet, ensuring a good user experience is a major challenge for network operators. Introduce the project's Unique Value Proposition: "We present Sentinel-QoS, an autonomous network orchestration agent that uses AI to intelligently manage traffic and guarantee Quality of Service for every user."(1:00-3:00) The Solution - Sentinel-QoS Architecture: Briefly present the high-level architecture using clear, animated diagrams. Explain the four-stage loop: Capture -> Classify -> Mark -> Shape. This demonstrates a well-thought-out design.(3:00-8:00) The Live Demonstration: This is the core of the video. Narrate a clear, compelling scenario using the live dashboard. For example: "We will now simulate two users on our network. User A, on the left, is starting a critical video conference call. User B, on the right, begins a large, non-essential file download. Watch the AI Classification Log. Sentinel-QoS instantly detects the new flows. It correctly identifies the video conference traffic and, as you can see in the Policy View, immediately marks it with the 'Expedited Forwarding' DSCP value. Now, look at the performance graphs. The video call's latency remains consistently low and stable, while the file download's bandwidth is dynamically shaped to ensure it doesn't interfere. We have successfully guaranteed the Quality of Experience for the critical application, automatically."(8:00-9:30) Technical Depth and Innovation: Briefly touch upon the key technical differentiators. Mention the use of a state-of-the-art hybrid CNN-LSTM model, the validation on the ISCX benchmark dataset, and the implementation using industry-standard tools and RFCs for DSCP values. This adds technical credibility.(9:30-10:00) Conclusion & Future Vision: Summarize the impact of the solution—a more efficient, intelligent, and user-friendly network. Briefly mention future work, such as integration into a full-scale SDN environment, to show a forward-looking vision.Technical Documentation and Code QualityClear, professional documentation and clean code are direct evaluation criteria and reflect the quality of the team's engineering practices.1A well-structured README.md file is essential. It should be the central document in the code repository and include the following sections:Project Overview: A concise summary of the project, its goals, and the Sentinel-QoS narrative.Architecture: A description of the system architecture, including the diagrams used in the demo video.Setup Instructions: Clear, step-by-step instructions on how to set up the development environment, including all dependencies.How to Run: Separate instructions for training the model from scratch and for running the final, integrated demonstration.Results: A summary of the model's performance on the test set, including key metrics and the confusion matrix.The code itself should be well-commented, particularly the model definition in the Keras/PyTorch script and the main orchestration logic in sentinel.py.A requirements.txt file must be included to allow for easy, one-command installation of all Python dependencies.Addressing Ethical Considerations and ScalabilityA winning project demonstrates an awareness of the broader context and implications of its technology.Ethical Considerations: The documentation and presentation must explicitly address the privacy implications of traffic analysis. The key statement to make is that Sentinel-QoS operates on encrypted traffic without performing decryption. It preserves user privacy and confidentiality by learning from the metadata and structural patterns of the traffic, not its content.4 The project's purpose should be framed positively as network management to improve user experience, not as a tool for surveillance.Scalability: The project should demonstrate a clear path to real-world deployment. The documentation should discuss how the current single-node prototype can be scaled horizontally. The most credible path is to propose a future architecture where the Sentinel-QoS classification engine runs as a microservice or application on top of a Software-Defined Networking (SDN) controller. In this model, the controller would receive flow statistics from network switches, send them to the AI engine for classification, and then push down the appropriate QoS flow rules to the switches centrally. This is a well-established paradigm for scalable, programmable network management and shows a sophisticated understanding of modern networking trends.16Hackathon Execution Timeline and MilestonesExecuting a complex project like Sentinel-QoS in a high-pressure, time-limited hackathon requires a disciplined and well-structured plan. This section outlines a rigorous 30-hour timeline, inspired by the rapid development cycles observed in competitive events 39, designed to guide the team's efforts and ensure all critical milestones are met. The timeline assumes a team of at least three members with designated roles: a Data Pipeline Lead, a Model Lead, and an Integration/Demo Lead.Hours 0-2: Strategy, Role Assignment, and Environment SetupObjective: To achieve strategic alignment and have all development environments fully operational.Milestones:The entire team conducts a final review of this execution plan, confirming the project architecture and strategy.Roles are formally assigned. The Data Pipeline Lead takes ownership of all data ingestion and preprocessing scripts. The Model Lead is responsible for implementing and training the AI engine. The Integration/Demo Lead is responsible for the QoS enforcement module, the final system integration, and the UI dashboard.All team members set up their Linux development environments, clone the project repository, and install all necessary dependencies from the requirements.txt file.The ISCXVPN2016 dataset download is initiated.Hours 2-8: Parallel Development of Core ComponentsObjective: To complete the foundational data pipeline and the standalone QoS enforcement module.Milestones:Data Pipeline Lead: The Python scripts for the entire data preprocessing pipeline (flow extraction, filtering, normalization, sessionization) are completed and tested on a small subset of the .pcap files. The full data generation process is started.Integration/Demo Lead: The setup_qos.sh script (using tc) and the apply_policy.py script (using iptables) are written and thoroughly tested in isolation using iperf and manual verification, as described in Phase III of the implementation plan.Model Lead: Begins implementing the CNN-LSTM model architecture in TensorFlow/Keras or PyTorch.Hours 8-20: Model Training and UI/UX DevelopmentObjective: To train the primary AI model while simultaneously building the demonstration front-end. This is the longest and most critical phase of parallel work.Milestones:Model Lead: With the preprocessed data now available from the Data Pipeline Lead, the full model training process is initiated. The lead monitors the training progress (loss and accuracy curves) and ensures that model checkpoints are being saved correctly.Integration/Demo Lead: Develops the Flask or Streamlit web dashboard. The basic layout, including placeholders for the live log, policy table, and performance graphs, is created. A simple API or data-sharing mechanism is implemented to allow the dashboard to receive updates from the main application.Data Pipeline Lead: Assists the Model Lead with any data-related issues and begins drafting the technical documentation (README.md), starting with the "Setup" and "Architecture" sections.Hours 20-26: System Integration and End-to-End TestingObjective: To merge all individual components into a single, functional end-to-end system and rigorously test its operation.Milestones:The best-performing trained model is loaded into the main sentinel.py orchestration script.The live packet capture module is integrated.The logic connecting the model's inference output to the QoS enforcement module is implemented and tested.The main orchestrator is connected to the web dashboard, feeding it real-time data.The entire team collaborates on debugging and running the full end-to-end test scenario on the simulated UE testbed. This involves generating multiple traffic types and verifying the correct behavior on the dashboard and through command-line monitoring tools.Hours 26-30: Final Polish, Video Production, and SubmissionObjective: To produce all final submission materials and package the project for the deadline.Milestones:The team finalizes the script for the 10-minute demo video.Multiple takes of the live demonstration are recorded using screen capture software. The best take is selected.The demo video is edited, adding the introductory and concluding slides, voiceover narration, and any necessary annotations.The technical documentation (README.md) is completed, and the code is cleaned, commented, and pushed to the final repository.The final submission package, including the video link and code repository URL, is prepared and submitted well before the deadline.Final Pitch and Presentation Strategy (for Phase 2)Success in the on-site finals hinges on the ability to deliver a clear, confident, and compelling presentation that effectively communicates the project's technical depth and strategic value. The Phase 2 evaluation criteria, with their heavy emphasis on "Unique Value Proposition" (30%), "Presentation & Flow" (30%), and "Demonstration" (30%), demand a performance that is as polished as the code itself.1 This section provides a strategy for structuring the final pitch and preparing for critical questions from the judges.Structuring the Presentation for Maximum ImpactThe presentation should be a masterclass in technical storytelling, guiding the audience from a relatable problem to an elegant and powerful solution.Start with the "Why": Begin not with technical details, but with the core problem. Frame it in terms the judges can immediately understand: "In an age where our work, education, and entertainment all depend on the internet, a poor connection is no longer a minor inconvenience—it's a critical failure. The explosion of diverse, encrypted applications has made it nearly impossible for networks to intelligently manage traffic and guarantee a good experience. This is the problem Sentinel-QoS was built to solve."Introduce the Vision: Present the Unique Value Proposition early and clearly. "Sentinel-QoS is not just another classifier. It is an autonomous network orchestration agent. It gives the network the intelligence to understand what users are doing and the power to proactively manage resources to ensure that a critical video conference is never disrupted by a background file download."The Centerpiece: A Flawless Live Demo: The live demonstration should be the longest and most memorable part of the presentation. Rehearse the scenario described for the demo video until it is seamless. Walk the judges through the dashboard, explaining each component and narrating the real-time actions of the system. Let the visual evidence on the performance graphs prove the system's effectiveness.Conclude with Impact and Vision: After the demo, summarize the key technical achievements and innovations. Reiterate the value proposition and conclude with a strong, forward-looking statement about the future of the project and its potential business or societal impact—enabling more reliable remote work, better telehealth services, and a smoother digital experience for everyone.Anticipating Judge QuestionsA prepared team can turn the Q&A session into an opportunity to further demonstrate their expertise. The following are likely questions, along with strategically sound, evidence-backed responses.Question: "Your model performs well on the ISCX dataset, but how would it handle a completely new application it has never seen before? How does it generalize?"Response: "That's an excellent question that touches on the critical challenge of generalization. Our deep learning approach, which learns fundamental patterns from raw bytes rather than hand-crafted features, is inherently more robust to new applications than traditional methods. However, no supervised model can perfectly classify something it's never seen. In a production environment, Sentinel-QoS would classify unknown traffic into a 'Default/Best Effort' category. The more advanced, long-term solution, which is a key area for future work, is to implement an autonomous update scheme. This involves using unsupervised clustering techniques to identify new, consistent patterns of unknown traffic and flagging them for an administrator to label. This creates a semi-supervised learning loop where the model can adapt and improve over time, a concept explored in recent research on self-evolving classifiers.22"Question: "What is the performance overhead of your system? Can it operate at line rate in a real-world network?"Response: "We designed the system with real-time performance as a primary constraint. The classification is based on only the first few packets of a flow, minimizing the data that needs to be processed. The inference latency for our CNN-LSTM model on a single flow instance is on the order of milliseconds on a standard CPU. For a high-volume gateway, the AI engine is designed to be offloaded to a GPU or other hardware accelerator, which is standard practice for deploying deep learning models in production.6 The QoS enforcement itself, using the kernel's native tc and iptables tools, is extremely efficient and operates at line rate. The AI engine makes a single decision per flow, and the kernel handles the per-packet enforcement, ensuring minimal performance impact."Question: "How would you deploy this solution in a large-scale enterprise or ISP network?"Response: "Our current prototype demonstrates the core functionality on a single gateway, which is suitable for a small office or home network. For large-scale deployment, the architecture is designed to evolve into a Software-Defined Networking (SDN) application.16 In an SDN environment, the network switches would be responsible for forwarding basic flow information (e.g., the first few packets of a new flow) to a centralized SDN controller. The Sentinel-QoS AI engine would run as an intelligent service on this controller. After classifying the flow, the controller would then push down the appropriate QoS flow rules to all relevant switches in the network path. This centralized, software-defined approach is the industry standard for managing complex network policies at scale and is a natural evolution for our system.17"Question: "You chose to use DSCP marking for policy enforcement. Why this specific mechanism?"Response: "We chose the Differentiated Services (DiffServ) framework and DSCP marking for three key reasons: standardization, scalability, and interoperability. DSCP is a mature IETF standard defined in multiple RFCs, ensuring that the markings produced by our system will be understood by a wide range of existing commercial routers and switches from different vendors.26 This avoids proprietary solutions and ensures interoperability. The DiffServ model is also highly scalable, as it only requires complex classification at the network edge while keeping the core network's function simple. This makes it the dominant QoS architecture in large networks today. By building our solution on this proven, standard foundation, we ensure that Sentinel-QoS is not just an academic prototype, but a practical solution designed for real-world network environments."